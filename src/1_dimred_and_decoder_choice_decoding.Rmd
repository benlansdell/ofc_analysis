---
title: "Ensembles and decoding"
output: html_notebook
params:
  fn: 'final_100207.Rds'
  path: '/media/core/core_operations/ImageAnalysisScratch/Schwarz/Cameron/ImagingData/'
---

Imports
```{r}
library(data.table)
library(ggplot2)
library(plotly)
library(htmltools)
library(reshape2)
library(gridExtra)
library(nnet)
library(cvms)

library(foreach)
library(parallel)
library(doParallel)

source('helper.R')
```

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

Set path to the data
```{r}
## Final day of training
#path = '/media/core/core_operations/ImageAnalysisScratch/Schwarz/Cameron/ImagingData/'
#fn = 'final_100207.Rds'

## Final day of training
#path = '/media/core/core_operations/ImageAnalysisScratch/Schwarz/Cameron/ImagingData2/'
#fn = 'final_010718.Rds'

path = params$path
fn = params$fn

dt = readRDS(paste0(path, fn))
dt
```

## In this notebook

For an individual recording, perform:

* Dimensionality reduction -- PCA

* Network state analysis (frame-frame similarities over trials)

* Linear decoding of events

## Basic stats

Number of trials
```{r}
unique(dt$`Trial Number`)
```

Number of cells
```{r}
uniqueN(dt$CellID)
```

Number of frames
```{r}
uniqueN(dt$frame)
```

Any missing frames?
```{r}
max(dt$frame) - min(dt$frame) + 1 - uniqueN(dt$frame)
```

Reward for this recording is on the:
```{r}
unique(dt$Reward)
```

## EDA 

### Dimensionality reduction

Form a wide data table
```{r}
dt_wide <- dt[,.(frame, CellID, dff, event, `Trial Number`)]
dt_wide <- data.table(dcast(dt_wide, frame + event + `Trial Number` ~ paste0("cell_", CellID), value.var="dff"))
cell_cols <- colnames(dt_wide)[4:length(colnames(dt_wide))]
index_cols <- colnames(dt_wide)[1:3]
zscored <- scale(dt_wide[,..cell_cols])
dt_zscored <- cbind(dt_wide[, ..index_cols], zscored)
```

Compute PCA of the data matrix
```{r}
prComp<-prcomp(zscored)
PoV <- prComp$sdev^2/sum(prComp$sdev^2)
plot(cumsum(PoV), xlab="# PCs", ylab="cumulative variance explained")
```

Plot projection onto first 2 PCs
```{r}
dt_pca = cbind(dt_wide[, ..index_cols], as.data.table(prComp$x))
ggplot(dt_pca, aes(x = PC1, y = PC2, color = event)) + geom_point(size = .5)
```

First 3 PCs (with plotly)
```{r}
fig <- plot_ly(dt_pca, x = ~PC1, y = ~PC2, z = ~PC3, color = ~event, size = 1)
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(xaxis = list(title = 'PC1'),
                     yaxis = list(title = 'PC2'),
                     zaxis = list(title = 'PC3'))) %>% toWebGL()
fig
```

Plot for separate trials
```{r}
for (tn in 1:12) {
  dt_pca_tn <- dt_pca[`Trial Number` == tn]
  fig <- plot_ly(dt_pca_tn, x = ~PC1, y = ~PC2, z = ~PC3, color = ~event, size = 1, mode = "lines", 
    line=list(width=~1))
  fig <- fig %>% add_markers()
  fig <- fig %>% layout(scene = list(xaxis = list(title = 'PC1'),
                       yaxis = list(title = 'PC2'),
                       zaxis = list(title = 'PC3'))) %>% toWebGL()
  print(fig)
}
```

### Frame-frame similarities between and within trials

To get an overall picture of the structure in the experiment, start by uniformly sub-sampling the data and then computing correlations in DFF signal between these frames. Here sub-sample by taking only every 10th frame.
```{r}
every_n_frames <- 10

dt_zscore_subsample = zscored[seq(1, nrow(zscored), every_n_frames), ]
idx_subsample <- dt_wide[seq(1, nrow(zscored), every_n_frames), ..index_cols]
idx_subsample$row = 1:nrow(idx_subsample)

zscore_corr_mat <- as.data.table(cor(t(dt_zscore_subsample)))
setnames(zscore_corr_mat, colnames(zscore_corr_mat), sub('.', '', colnames(zscore_corr_mat)))
cns <- colnames(zscore_corr_mat)
zscore_corr_mat <- cbind(data.table(row = 1:length(zscore_corr_mat)), zscore_corr_mat)
zscore_corr_mat = data.table(melt(zscore_corr_mat, measure.vars = cns, id.vars = c("row"), variable.name = "col"))
zscore_corr_mat[, col := as.integer(col)] 
zscore_corr_mat <- merge(zscore_corr_mat, idx_subsample, by = "row")[, .(row, col, value, frame, event, `Trial Number`)]
setnames(zscore_corr_mat, c("frame", "event", "Trial Number"), c("frame_row", "event_row", "trial_num_row"))
zscore_corr_mat <- merge(zscore_corr_mat, idx_subsample, by.x = "col", by.y = "row")[, .(col, row, value, frame_row, event_row, trial_num_row, frame, event, `Trial Number`)]
setnames(zscore_corr_mat, c("frame", "event", "Trial Number"), c("frame_col", "event_col", "trial_num_col"))
```

Plot correlations for all trials
```{r}
p1 <- ggplot(zscore_corr_mat) + geom_raster(aes(x = row, y = col, fill = value))
p1
```

Compute multi-dimensional scaling (MDS) embedding of this correlation matrix. (Try to represent this distance matrix as a 2D plot)
```{r}
fit <- cmdscale(1-cor(t(dt_zscore_subsample)), eig=TRUE, k=2)
x <- fit$points[,1]
y <- fit$points[,2]
#dt_zscore_subsample
ggplot(data.frame(x = fit$points[,1], y = fit$points[,2], color = idx_subsample$event, trial = as.factor(idx_subsample$`Trial Number`)), aes(x = x, y = y, color = color)) + geom_point(size = 1)
```

Average correlation over all trials by event type
```{r}
mean_corrs = zscore_corr_mat[, .(mean_corr = mean(value)), by = .(event_row, event_col)]
p1 <- ggplot(mean_corrs) + geom_raster(aes(x = event_row, y = event_col, fill = mean_corr)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p1
```

Hierarchical clustering of this correlation matrix. Neighbors here reflect trial structure.
```{r}
distanceMatrix <- as.dist(as.matrix(1-mean_corrs_wide[,2:ncol(mean_corrs_wide)]))
clusters <- hclust(distanceMatrix)
plot(clusters)
```

These results may be affected by the proportion of time spent in each of the event types. Longer events may tend to show more diverse activity patterns, just because they occur over longer times. We can repeat the analysis, focusing on a fixed time window at the onset of each event. 

## Analysis of activity near event onsets

Focus on the first 2 seconds of an event onset.
```{r}
event_onset_window_size <- 2
fps <- 20

#For each trial, find the first time each event occurs
event_onset_times <- dt[, .(start_time = min(frame)), by = .(`Trial Number`, event)]
dt_ <- merge(dt, event_onset_times, by = c("Trial Number", "event"))
dt_event_onset = dt_[(frame - start_time > 0) & (frame - start_time < (fps*event_onset_window_size)), ]
dt_event_onset
```

Now repeat the above analyses

### Dimensionality reduction

Form a wide data table
```{r}
dt_wide <- dt_event_onset[,.(frame, CellID, dff, event, `Trial Number`)]
dt_wide <- data.table(dcast(dt_wide, frame + event + `Trial Number` ~ paste0("cell_", CellID), value.var="dff"))
cell_cols <- colnames(dt_wide)[4:length(colnames(dt_wide))]
index_cols <- colnames(dt_wide)[1:3]
zscored <- scale(dt_wide[,..cell_cols])
dt_zscored <- cbind(dt_wide[, ..index_cols], zscored)
```

Compute PCA of the data matrix
```{r}
prComp<-prcomp(zscored)
PoV <- prComp$sdev^2/sum(prComp$sdev^2)
plot(cumsum(PoV), xlab="# PCs", ylab="cumulative variance explained")
```

Plot projection onto first 2 PCs
```{r}
dt_pca = cbind(dt_wide[, ..index_cols], as.data.table(prComp$x))
ggplot(dt_pca, aes(x = PC1, y = PC2, color = event)) + geom_point(size = .5)
```

First 3 PCs (with plotly)
```{r}
fig <- plot_ly(dt_pca, x = ~PC1, y = ~PC2, z = ~PC3, color = ~event, size = 1)
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(xaxis = list(title = 'PC1'),
                     yaxis = list(title = 'PC2'),
                     zaxis = list(title = 'PC3'))) %>% toWebGL()
fig
```

Plot for separate trials
```{r}
for (tn in 1:12) {
  dt_pca_tn <- dt_pca[`Trial Number` == tn]
  fig <- plot_ly(dt_pca_tn, x = ~PC1, y = ~PC2, z = ~PC3, color = ~event, size = 1, mode = "lines", 
    line=list(width=~1))
  fig <- fig %>% add_markers()
  fig <- fig %>% layout(scene = list(xaxis = list(title = 'PC1'),
                       yaxis = list(title = 'PC2'),
                       zaxis = list(title = 'PC3'))) %>% toWebGL()
  print(fig)
}
```

### Frame-frame similarities between and within trials

To get an overall picture of the structure in the experiment, start by uniformly sub-sampling the data and then computing correlations in DFF signal between these frames. Here sub-sample by taking only every 10th frame.
```{r}
every_n_frames <- 1

dt_zscore_subsample = zscored[seq(1, nrow(zscored), every_n_frames), ]
idx_subsample <- dt_wide[seq(1, nrow(zscored), every_n_frames), ..index_cols]
idx_subsample$row = 1:nrow(idx_subsample)

zscore_corr_mat <- as.data.table(cor(t(dt_zscore_subsample)))
setnames(zscore_corr_mat, colnames(zscore_corr_mat), sub('.', '', colnames(zscore_corr_mat)))
cns <- colnames(zscore_corr_mat)
zscore_corr_mat <- cbind(data.table(row = 1:length(zscore_corr_mat)), zscore_corr_mat)
zscore_corr_mat = data.table(melt(zscore_corr_mat, measure.vars = cns, id.vars = c("row"), variable.name = "col"))
zscore_corr_mat[, col := as.integer(col)] 
zscore_corr_mat <- merge(zscore_corr_mat, idx_subsample, by = "row")[, .(row, col, value, frame, event, `Trial Number`)]
setnames(zscore_corr_mat, c("frame", "event", "Trial Number"), c("frame_row", "event_row", "trial_num_row"))
zscore_corr_mat <- merge(zscore_corr_mat, idx_subsample, by.x = "col", by.y = "row")[, .(col, row, value, frame_row, event_row, trial_num_row, frame, event, `Trial Number`)]
setnames(zscore_corr_mat, c("frame", "event", "Trial Number"), c("frame_col", "event_col", "trial_num_col"))
```

Plot correlations for all trials
```{r}
p1 <- ggplot(zscore_corr_mat) + geom_raster(aes(x = row, y = col, fill = value))
p1
```

And for each trial, separately
```{r}
for (trial in unique(zscore_corr_mat$trial_num_col)) {
  p1 <- ggplot(zscore_corr_mat[trial_num_row == trial & trial_num_col == trial]) + geom_raster(aes(x = row, y = col, fill = value)) + ggtitle(paste('Trial:', trial))
  print(p1)
}
```

Compute multi-dimensional scaling (MDS) embedding of this correlation matrix. (Try to represent this distance matrix as a 2D plot)
```{r}
fit <- cmdscale(1-cor(t(dt_zscore_subsample)), eig=TRUE, k=2)
x <- fit$points[,1]
y <- fit$points[,2]
#dt_zscore_subsample
ggplot(data.frame(x = fit$points[,1], y = fit$points[,2], color = idx_subsample$event, trial = as.factor(idx_subsample$`Trial Number`)), aes(x = x, y = y, color = color)) + geom_point(size = 1)
```

Average correlation over all trials by event type
```{r}
mean_corrs = zscore_corr_mat[, .(mean_corr = mean(value)), by = .(event_row, event_col)]
p1 <- ggplot(mean_corrs) + geom_raster(aes(x = event_row, y = event_col, fill = mean_corr)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p1
```

Hierarchical clustering of this correlation matrix. Neighbors here reflect trial structure.
```{r}
distanceMatrix <- as.dist(as.matrix(1-mean_corrs_wide[,2:ncol(mean_corrs_wide)]))
clusters <- hclust(distanceMatrix)
plot(clusters)
```


## Building a linear decoder

Use leave-one-trial out CV to fit a logistic regression model to the z-scored dffs

```{r}
max_iter = 1000
weight_decay = 0.1
trials = unique(dt_zscored$`Trial Number`)
```

Uses a parallel code to fit all folds at once
```{r}
n_workers = length(trials)
cl <- makeCluster(n_workers)
registerDoParallel(cl)

evals = foreach(trial = trials, .packages = c("data.table", "nnet", "cvms")) %dopar% {

  print(paste("Training fold", trial))
  train_data = dt_zscored[`Trial Number` != trial]
  test_data = dt_zscored[`Trial Number` == trial]
  test_data[ ,c("frame","Trial Number") := NULL]
  train_data[ ,c("frame","Trial Number") := NULL]
  test_data[ , event := as.factor(event)]
  train_data[ , event := as.factor(event)]
  
  model_multi = multinom(event ~ ., train_data, trace = FALSE, maxit=max_iter, MaxNWts=84581, decay = weight_decay)

  model_preds <- predict(model_multi, newdata = test_data)
  true_event <- test_data$event

  fold_results <- data.table(pred = as.character(model_preds), gt = as.character(true_event))
  eval <- evaluate(fold_results,
                   target_col = "gt",
                   prediction_cols = "pred", type = "multinomial")
  return(eval)
}
evals = rbindlist(evals)
stopCluster(cl)
```

Plot confusion matrices
```{r}
for (idx in 1:12) {
  print(plot_cm(dt_zscored, evals, idx))
}
```

## Decode direction taken given earlier activity

* Given pre-decision activity, can we predict which choice it will make?

For each trial, find the decision is made
Train a decoder based on a certain number of seconds just before the decision is made
How well can we predict the choice (using LOTO-CV)

```{r}
print(dt[, min(frame), by = .(`Trial Number`, event)], topn = 20)
dt
```

```{r}
ggplot(dt[`Trial Number` <= 1], aes(x = `Centre position X`, y = `Centre position Y`, color = event)) + geom_point()
```


Can we predict 'value'. Namely 'reward'. But, for a given set of trials, reward is the spout chosen -- e.g. choose right = reward, choose left = no reward. So, predicting value in this case is just predicting choice made. 

```{r}
training_window_size <- 3
fps <- 20

dt_start_ends <- dt[event == 'In Start', .(last_start_frame = max(frame)), .(`Trial Number`)]
trial_choice_left <- dt[event == 'In Left decision', .(min_frame = min(frame), choice = "left"), .(`Trial Number`)]
trial_choice_right <- dt[event == 'In Right decision', .(min_frame = min(frame), choice = "right"), .(`Trial Number`)]
trial_choice <- rbind(trial_choice_left, trial_choice_right)

#trial_choice

dt_ <- merge(dt, trial_choice, by = "Trial Number")
dt_ <- merge(dt_, dt_start_ends, by = "Trial Number")

dt_startonly <- dt_[(event == 'In Start') & (frame >= last_start_frame - fps*training_window_size), ]

dt_wide <- dt_startonly[,.(frame, CellID, dff, event, `Trial Number`, choice)]
dt_wide <- data.table(dcast(dt_wide, frame + event + `Trial Number` + choice ~ paste0("cell_", CellID), value.var="dff"))
cell_cols <- colnames(dt_wide)[5:length(colnames(dt_wide))]
index_cols <- colnames(dt_wide)[1:4]
zscored_start <- scale(dt_wide[,..cell_cols])
dt_zscored_start <- cbind(dt_wide[, ..index_cols], zscored_start)
dt_zscored_start
```

```{r}
weight_decay <- 1
n_pcs <- 20

n_workers = length(trials)
cl <- makeCluster(n_workers)
registerDoParallel(cl)

evals_start = foreach(trial = trials, .packages = c("data.table", "nnet", "cvms", "e1071")) %dopar% {

  print(paste("Training fold", trial))
  test_data = dt_zscored_start[`Trial Number` == trial]
  train_data = dt_zscored_start[`Trial Number` != trial]

  test_data[ ,c("frame", "Trial Number", "event") := NULL]
  train_data[ ,c("frame", "Trial Number", "event") := NULL]

  pr_comp_training <- prcomp(train_data[,.SD, .SDcols = !c('choice')])
  train_data_pca <- scale(train_data[,.SD, .SDcols = !c('choice')], pr_comp_training$center, pr_comp_training$scale) %*% pr_comp_training$rotation 
  test_data_pca <- scale(test_data[,.SD, .SDcols = !c('choice')], pr_comp_training$center, pr_comp_training$scale) %*% pr_comp_training$rotation 

  test_data <- cbind(test_data[, .(choice)], as.data.table(test_data_pca)[, 1:n_pcs])
  train_data <- cbind(train_data[, .(choice)], as.data.table(train_data_pca)[, 1:n_pcs])

  test_data[, choice := as.factor(choice)]
  train_data[, choice := as.factor(choice)]
  
  weightings <- data.table(choice = train_data$choice, weight = 1)
  weightings[choice == 'right', weight := 1]  
  weightings <- weightings$weight
  #model_multi = multinom(choice ~ ., train_data, trace = FALSE, maxit=max_iter, MaxNWts=84581, decay = weight_decay)
  #model_multi = multinom(choice ~ ., train_data, trace = FALSE, maxit=max_iter, MaxNWts=84581, decay = weight_decay, weights = weightings)

  weightings <- table(train_data$choice)  # the weight vector must be named with the classes names
  weightings[1] <- 10000    # a class left mismatch has a terrible cost
  weightings[2] <- 1     # a class +1 mismatch not so much...
  
  #model_multi = svm(choice ~ ., train_data, class.weights = weightings, cost = 0.01)
  model_multi = svm(choice ~ ., train_data, class.weights = 'inverse', cost = 3)
  model_preds <- predict(model_multi, newdata = test_data)
  
  true_event <- test_data$choice

  fold_results <- data.table(pred = as.character(model_preds), gt = as.character(true_event))
  eval <- evaluate(fold_results,
                   target_col = "gt",
                   prediction_cols = "pred", type = "multinomial")
  eval <- as.data.table(eval)
  eval[, `Trial Number` := trial]
  eval[, choice := unique(test_data[, .(choice)])]
  return(eval)
}
evals_start = rbindlist(evals_start)
stopCluster(cl)
evals_start
```


Plot confusion matrices
```{r}
for (idx in 1:12) {
  print(plot_cm(dt_zscored_start, evals_start, idx))
}
```

## Outstanding analyses

* Some summary statistics from this analysis, to summarize the recording, so we can compare from day to day.
* * Each event's: within cluster variance
* * How many trials can we predict above chance performance?
* * PCA: how many components are significant

# References

* Kingsbury et al 2019. Correlated Neural Activity and Encoding of Behavior across Brains of Socially Interacting Animals. 

PC population responses

* Kingsbury et al 2020. Cortical Representations of conspecific sex shape social behavior. 

PC population responses. Also an LDA decoder 

### Appendix

Plots of individual trials

And for each trial, separately
```{r}
for (trial in unique(zscore_corr_mat$trial_num_col)) {
  p1 <- ggplot(zscore_corr_mat[trial_num_row == trial & trial_num_col == trial]) + geom_raster(aes(x = row, y = col, fill = value)) + ggtitle(paste('Trial:', trial))
  print(p1)
}
```

