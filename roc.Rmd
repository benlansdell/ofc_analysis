---
title: "ROC analysis"
output: html_notebook
---

## ROC analysis for cells

Goals of notebook:
* Try out ROC analysis on single recording
* Study questions of normalization for method

```{bash}
ls /media/core/core_operations/ImageAnalysisScratch/Schwarz/Cameron/ImagingData/
```

```{r}
fn = 'final_060603.Rds'
```

Load data

```{r}
load(file = sprintf("./intermediate/0_datatablesfor_%s", fn))
```

Imports
```{r}
library(hash)
library(ROCR)
#And others...

```

The loaded data table
```{r}
ds
```

### Preprocessing of signal

How much variability is there between trials for a given cell?

```{r}
a = ds[,.(mn = mean(dff), sd = sd(dff)), by = .(CellID, `Trial Number`)]
a[CellID == 1]
```

How should we normalize? In particular, should we normalize by trial?

If the question is: is this cell responsive on this particular trial, then we can indeed normalize over each trial and run the ROC analysis over each cell. Although, as argued below, the scaling in this case doesn't matter, so this shouldn't make any difference. Further, on a per trial basis, we have less data to generate useful ROC curves.

Alternatively, if the question is: is this cell responsive over all the trials, then should we normalize by each trial?

This depends on assumptions we make about the data. If we assume the absolute amount of activity is the proxy for response, then normalizing per trial seems to be a bad idea. This is because normalizing each trial separately, then running an ROC analysis over all trials pooled together, will result in magnitudes for trials when the cell is relatively silent being brought up to equal size to trials when the cell is active. If the quiescent trial is indeed not responding to the cue of interest, this is simply adding noise to the signal to be decoded. 

On the other hand, if we assume something like the relative change in activity is the relevant indicator of a cell's response, then normalizing per trial may be a good idea. However, if this were the assumption, then an ROC-based method that just ranks things according to their intensity does not seem like the most appropriate method. Some sort of decoder that took into account the activity relative to a moving average baseline, or something, would be more appropriate. 

Normalize: (z-score)

```{r}
ds[, dff_zs := (dff - mean(dff))/sd(dff), by = `CellID`]
ds
```

### ROC curves

Compute the ROC curves. The signal is treated as a binary classifier for the experimental state of interest. Here, the states of interest are the first phases of the l/r spout states. After normalizing, we treat the signal as a simple binary classifier. That is, if it is above a given amount then it counts as 1, otherwise 0. We can use this to generate an ROC curve, which indicates how well that cell classifies times as the event of interest or not. The ROC AUC is used as a measure of cell responsiveness. 

```{r}
#See comment section here: https://rviews.rstudio.com/2019/03/01/some-r-packages-for-roc-curves/
#This is simple, but not efficient for large lists...Better to use ROCR package, as below
simple_roc <- function(labels, scores){
Labels <- labels[order(scores, decreasing=TRUE)]
unique(data.frame(
FPR=cumsum(!Labels)/sum(!Labels),
TPR=cumsum(Labels)/sum(Labels))
)}
```

Make a dictionary of ROC curves for each cellID
```{r}
roc_curves = hash()
per_cell_ds = split(ds, f = ds$CellID)
cells = unique(ds$CellID)
```

```{r}
for (dss in per_cell_ds) {
  p = performance(prediction(dss$dff_zs, dss$rspout_first), "tpr", "fpr") 
  q = performance(prediction(dss$dff_zs, dss$rspout_first), "auc") 
  roc_curves[dss[1,CellID]] = list(p, q)
}
```

Plot the ROC curves for all cells
```{r fig6, fig.height = 6, fig.width = 6}
plot(roc_curves[['1']][[1]])
lapply(cells, function(x) plot(roc_curves[[x]][[1]], add = TRUE));
```

Now we can make a new data table to house the results of our analysis...

```{r}
aucs = sapply(cells, function(x) roc_curves[[x]][[2]]@y.values[[1]])
dt_roc = data.table(CellID = cells, AUC = aucs, null_quantile = numeric(), pos_resp = numeric(), neg_resp = numeric())
dt_roc
```

### Generation of null-distributions for each cell

Now, for each cell, we perform N random shifts of the signal, and recompute the AUC. 

This gives us a null distribution from which we can judge an AUC as significant or not. 

(In the paper [1], N = 1000)

First confirm what the method looks like for a few cells.

```{r}
N = 50

cycle = function (x,i) c(x[-(0:i)], x[0:i])

n_cells = 1
cell <- sample(unique(ds$CellID), n_cells, replace=F)

#Can think about how to parallelize this...
print("Computing null distributions for AUC for cell:")
print(cell)

dss = ds[CellID == cell]
aucs = c()
pred_real = performance(prediction(dss$dff_zs, dss$rspout_first), "tpr", "fpr")
plot(pred_real, colorize = TRUE)
for (j in 1:N) {
  #Perform shuffle of data...
  rand_idx = ceiling(runif(1, 0, length(dss$dff_zs)))
  shuffle = cycle(dss$dff_zs, rand_idx)
  pred = performance(prediction(shuffle, dss$rspout_first), "tpr", "fpr")
  auc = performance(prediction(shuffle, dss$rspout_first), "auc")@y.values[[1]]
  aucs = c(aucs, auc)
  plot(pred, add = TRUE)
}

this_auc = dt_roc[CellID == cell, AUC]
quantile = sum(aucs < this_auc)/N

plot(pred_real, colorize = TRUE, add = TRUE)
title(sprintf("Cell %s, AUC: %f, quantile: %f", cell, this_auc, quantile))
```

```{r}
hist(aucs, breaks = 10)
title(sprintf("Cell %s", cell))
```

Repeat for all cells

```{r}
library(foreach)
library(parallel)
library(doParallel)

#Either: save each cell data table in file (fread, fwrite), or pass list of cells

cl <- makeCluster(20)
registerDoParallel(cl)
```

```{r}
N = 1000
null_rocs = foreach(idx = 1:length(per_cell_ds), .packages = c("data.table", "ROCR")) %dopar% {
  
  dss = per_cell_ds[[idx]]
  cell = dss[1, CellID]
  aucs = c()
  print(cell)
  for (j in 1:N) {
    #Perform shuffle of data...
    rand_idx = ceiling(runif(1, 0, length(dss$dff_zs)))
    shuffle = cycle(dss$dff_zs, rand_idx)
    auc = performance(prediction(shuffle, dss$rspout_first), "auc")@y.values[[1]]
    aucs = c(aucs, auc)
  }
  this_auc = dt_roc[CellID == cell, AUC]
  quantile = sum(aucs < this_auc)/N
  return(data.table(CellID = cell, null_quantile = quantile))
}

```

```{r}
#null_rocs = rbindlist(null_rocs)
dt_roc[,null_quantile := NULL]
dt_roc = merge(dt_roc, null_rocs, by = 'CellID')
dt_roc
```


```{r}
alpha = 0.05

dt_roc[,pos_resp := null_quantile > 1-alpha]
dt_roc[,neg_resp := null_quantile < alpha]
```

```{r}
dt_roc
```

### Summarize the significantly responding cells

How many positively and negatively responding cells are there? Out of 192

```{r}
print(sum(dt_roc$pos_resp))
print(sum(dt_roc$neg_resp))
```

### Analysis question: ROC curves, probability and deconvolution

Deconvolution, as used in spike inference methods (e.g. OASIS), will return a signal in the original signal's space. Not interpretable as a probability.

But, an ROC curve need not be computed using thresholds on probabilities. Any score generated by a model/test can be used. For instance in diagnostic medical tests, concentration cutoffs are used. 

### Analysis question: does the normalization method matter?

The ROC curve is invariant to transformations of the signal of the form $f(x) = ax + b, a > 0$ ('orientation preserving affine transformations'). This means any choice of scaling/translation will produce the same ROC curve. And thus, in theory, z-scoring per cell or z-scoring over all cells shouldn't matter.

Why is this the case? A short answer can be seen just by looking at a simple implementation of how to compute the ROC curve:
```
simple_roc <- function(labels, scores){
  Labels <- labels[order(scores, decreasing=TRUE)]
  unique(data.frame(
  FPR=cumsum(!Labels)/sum(!Labels),
  TPR=cumsum(Labels)/sum(Labels))
)}
```
Only the order of the scores matters, not their value. Rescaling doesn't affect the order. 

A more detailed answer is as follows. Let $x$ be the signal, and $z = f(x)$ some transformed signal of the form above. Every point on the ROC curve corresponds to the performance of a classifier obtained by setting the threshold to a given value (or a range of values). Consider the classifier based on $x$: 
$$
g_\theta(x) = \mathbb{I}(x \ge \theta)
$$
Since $f$ is monotonically increasing, each classifier in $x$ has an equivalent classifer in $z$. That is, 
$$
g_\theta(x) = \mathbb{I}(x \ge \theta) = \mathbb{I}(f(x) \ge f(\theta)) = \mathbb{I}(z \ge f(\theta)) = h_{f(\theta)}(z)
$$
and similarly for each classifier in $z$. This means each point on $g$'s ROC curve has an point on $h$'s ROC curve, and vice versa. Thus they are the same curve.

Thus in theory the method is scale invariant. However, when performed numerically, z-scoring for all cells together, for instance, may result in poor resolution of some ROC curves, depending on how the curve is computed. This is because z-scoring all cells together will result in the relatively quiescent cells being at low magnitude at all times. Computing the ROC curves by a threshold common to both a quiet cell and a non-quiet cell will not be numerically well resolved over the quiet cell's smaller range. This is only an issue for the 'naive' implementation of computing an ROC curve (just manually sliding a threshold over the range of the data).

### TODO

* Redo this analysis for both lspout and rspout events
* Run for higher N
* Make more general analysis pipeline that can handle any event of interest, pool data over multiple recordings
* Consider alternative methods that may also work: 
** Correlation rank
** Bandpass filter before giving to ROC method... removes slow fluctuations in intensity?
** Neural decoding methods? Can decode events as function of neural activity?
** GLM. Could include behavioral variables, as well as events
** Some other statistical analysis that says 'activity is significantly above baseline'
** What else?

### References 

[1] "Cortical Representations of Conspecific Sex Shape Social Behavior" Kingsbury et al 2020